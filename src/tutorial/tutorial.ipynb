{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISE Camp 2018: Introduction to Flor!\n",
    "\n",
    "\n",
    "Welcome to RISE Camp 2018! Flor is a system for managing workflow development within the machine learning lifecycle. This tool enables data scientists to describe ML workflows as directed acyclic graphs (DAGs) of Actions, Artifacts, or Literals and to experiment with different configurations quickly by running multi-trial experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![object model](./object_model.png)\n",
    "<center><i>Artifacts in rectangles; Literals in underline; Actions in circles</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to help you use Flor in order to navigate through different parts of the data science lifecycle.\n",
    "\n",
    "As you work through this notebook, you will learn:\n",
    "\n",
    "* How to define/use experiments, literals, artifacts and actions.\n",
    "* How to run experiments with different configurations.\n",
    "* Compare models with other past versions in order to select the best model.\n",
    "\n",
    "We will be working with a ratings dataset. Our goal is to predict whether a movie review is positive or negative based on its text.\n",
    "\n",
    "**Data science is a collaborative activity - we encourage you to work with those around you and ask questions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context: Introduction & Background\n",
    "\n",
    "In this tutorial, as in many \"real-world\" cases, you'll be joining an in-progress model development effort. Bob, a fellow member of your team, has already attempted two different data-preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>data_loc</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>intermediate_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second_preproc</td>\n",
       "      <td>tutorial_4572332664.ipynb</td>\n",
       "      <td>data_4550917536.json</td>\n",
       "      <td>data_clean_X_112511176888.json</td>\n",
       "      <td>data_clean_y_112511176944.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_preproc</td>\n",
       "      <td>tutorial_112094533448.ipynb</td>\n",
       "      <td>data_112094533896.json</td>\n",
       "      <td>data_clean_X_112094534512.json</td>\n",
       "      <td>data_clean_y_112094533392.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             utag                preprocessing                data_loc  \\\n",
       "0  second_preproc    tutorial_4572332664.ipynb    data_4550917536.json   \n",
       "1   first_preproc  tutorial_112094533448.ipynb  data_112094533896.json   \n",
       "\n",
       "                   intermediate_X                  intermediate_y  \n",
       "0  data_clean_X_112511176888.json  data_clean_y_112511176944.json  \n",
       "1  data_clean_X_112094534512.json  data_clean_y_112094533392.json  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This command just tells flor to summarize the various versions of the experiment named 'risecamp_demo'\n",
    "\"\"\"\n",
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the output. The first column, `utag`, lists the different versions of the experiment by name. We can see there are two past versions of the experiment 'risecamp_demo': `first_preproc`, and `second_preproc`. We can also see the artifacts that were involved in the experiment, either as inputs or outputs to some action: `data_loc`, `preprocessing`, `intermediate_X`, and `intermediate_Y`. The name of such artifacts corresponds to the name of the columns in the summary dataframe, we will discuss the values of the cells later in the tutorial. Although we now know there were four (4) artifacts involved in each past version of the experiment, from the summary alone, we cannot (in general) infer how an artifact was produced or consumed in an experiment -- that is, we cannot infer the structure of the experiment computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the structure of the experiment computation graph, for each of the two previous versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"268pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 267.50 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 263.5,-184 263.5,4 -4,4\"/>\n",
       "<!-- 3 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"127.5,-180 32.5,-180 32.5,-144 127.5,-144 127.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"80\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial.ipynb</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"130\" cy=\"-90\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocessing</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M92.6171,-143.8314C98.4049,-135.497 105.3773,-125.4567 111.7249,-116.3162\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.7309,-118.1235 117.5601,-107.9134 108.9813,-114.1307 114.7309,-118.1235\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"214,-180 146,-180 146,-144 214,-144 214,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data.json</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.3829,-143.8314C161.5951,-135.497 154.6227,-125.4567 148.2751,-116.3162\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"151.0187,-114.1307 142.4399,-107.9134 145.2691,-118.1235 151.0187,-114.1307\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"122,-36 0,-36 0,0 122,0 122,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_X.json</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M113.297,-72.5708C104.9257,-63.8355 94.6292,-53.0914 85.3928,-43.4534\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.7158,-40.8188 78.2697,-36.0206 82.6618,-45.6622 87.7158,-40.8188\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"259.5,-36 140.5,-36 140.5,0 259.5,0 259.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_y.json</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M146.945,-72.5708C155.4377,-63.8355 165.8834,-53.0914 175.2536,-43.4534\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.0187,-45.6304 182.48,-36.0206 172.9997,-40.7508 178.0187,-45.6304\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f9a4c12b518>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('risecamp_demo').plot('first_preproc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"268pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 267.50 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 263.5,-184 263.5,4 -4,4\"/>\n",
       "<!-- 3 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"127.5,-180 32.5,-180 32.5,-144 127.5,-144 127.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"80\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial.ipynb</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"130\" cy=\"-90\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocessing</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M92.6171,-143.8314C98.4049,-135.497 105.3773,-125.4567 111.7249,-116.3162\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.7309,-118.1235 117.5601,-107.9134 108.9813,-114.1307 114.7309,-118.1235\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"214,-180 146,-180 146,-144 214,-144 214,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data.json</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.3829,-143.8314C161.5951,-135.497 154.6227,-125.4567 148.2751,-116.3162\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"151.0187,-114.1307 142.4399,-107.9134 145.2691,-118.1235 151.0187,-114.1307\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"122,-36 0,-36 0,0 122,0 122,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_X.json</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M113.297,-72.5708C104.9257,-63.8355 94.6292,-53.0914 85.3928,-43.4534\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.7158,-40.8188 78.2697,-36.0206 82.6618,-45.6622 87.7158,-40.8188\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"259.5,-36 140.5,-36 140.5,0 259.5,0 259.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_y.json</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M146.945,-72.5708C155.4377,-63.8355 165.8834,-53.0914 175.2536,-43.4534\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.0187,-45.6304 182.48,-36.0206 172.9997,-40.7508 178.0187,-45.6304\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f9a1a9d8eb8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('risecamp_demo').plot('second_preproc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import scipy.sparse\n",
    "\n",
    "#Pre-processing imports\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#Model training and testing imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the notebook name has not already been set, you are able to set the name in code. \n",
    "flor.setNotebookName('tutorial.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Before building our model, we will define a pipeline to pre-process our text data. We have used the following techniques to pre-process the text reviews:\n",
    "* Removal of Stop Words\n",
    "* Stemming (reducing inflected words to their stem)\n",
    "* Lemmatization (group together inflected forms of a words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me\n",
    "from florfunctions import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "We have created a function to split our data into train/test sets. Since we would like this to be a Flor Function, we must wrap it with the @flor.func decorator so it is able to be referenced by Flor actions. **Please navigate to the florfunctions.py file and wrap the `traintest_split` function with the Flor decorator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me\n",
    "from florfunctions import traintest_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "Now, we can create a Flor function to train and evaluate a model to classify reviews into rating buckets. **Please navigate to the florfunctions.py file and complete the `train_test` function; fill in the Random Forest model with an n_estimators parameter of 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from florfunctions import train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup\n",
    "\n",
    "Finally, we will now define our Flor experiment using the Flor functions we created above. Proceed through the following cells and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = flor.Experiment('risecamp_demo').__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the data we want to analyze. We can load the data by creating **artifacts**, which are pointers to data we want. In this case, we have already generated cleaned data from a previous experiment run; we can retrieve the cleaned data by referencing the tag of the particular run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines preprocessing action and resulting intermediary artifacts\n",
    "data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag=\"first\")\n",
    "data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data points, we need to perform a train/test split. Using the `traintest_split` function we imported earlier, let's create a flor action as well as the intermediary artifacts generated by the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintest_split is the function to run, data_x and data_y are arguments\n",
    "do_split = ex.action(traintest_split, [data_x, data_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artifacts have a pointer (filename), internal name, and (optional) parent\n",
    "X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "y_test = ex.artifact('y_test.json', 'y_test', do_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can specify the hyperparameter with a **literal**, an explicit value stored in Flor, and create an action for our `train_test` function and an artifact for our result. We can wrap up the experiment and close it with `__exit__()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "#Define the model training and evaluation action and final artifacts\n",
    "do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, hyperparameter])\n",
    "report = ex.artifact('report.csv', 'report', do_test)\n",
    "score = ex.literal(name='score', parent=do_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.__exit__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull\n",
    "\n",
    "Finally, we are ready to run the experiment! We can do so by running `pull()` on our output artifacts. Before doing this, however, it is helpful to use `plot()` to generate a florplan, a graph representation of the artifact's lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the experiment\n",
    "score.pull('first_pull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull again, trying a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag=\"second\")\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag=\"second\")\n",
    "    \n",
    "    #traintest_split is the function to run, data_x and data_y are arguments\n",
    "    do_split = ex.action(traintest_split, [data_x, data_y])\n",
    "    \n",
    "    #artifacts have a pointer (filename), internal name, and (optional) parent\n",
    "    X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "    X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "    y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "    y_test = ex.artifact('y_test.json', 'y_test', do_split)\n",
    "    \n",
    "    hyperparameter = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "    #Define the model training and evaluation action and final artifacts\n",
    "    do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, hyperparameter])\n",
    "    report = ex.artifact('report.csv', 'report', do_test)\n",
    "    score = ex.literal(name='score', parent=do_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.pull('second_pull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    report = ex.artifact('report.csv', 'report', utag='first_pull')\n",
    "report.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    report = ex.artifact('report.csv', 'report', utag='second_pull')\n",
    "report.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the data: since it's the only thing that we changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    data_x1 = ex.artifact('data_clean_X.json', 'intermediate_X', utag=\"first\")\n",
    "    data_x2 = ex.artifact('data_clean_X.json', 'intermediate_X', utag=\"second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x1.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x2.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Flor makes it convenient to run models using different hyperparameters and track the results. In the `train_test` we created function, notice that we pass in `hyperparameters` in addition to the train and test data. These hyperparameters will allow us to tune our model and track results with ease; let's define them in our experiment setup.\n",
    "\n",
    "Notice that the Random Forest Classifier contains `n_estimators` as a hyperparameter. We would like to tune this hyperparameter and track model performance. In order to specify the hyperparameters, we must make a `literalForEach` within our experiment. **Fill in the `literalForEach` with values 5, 50 and 75 within the experiment below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: We have copied the same experiment below for convenience.\n",
    "#We can also create flor experiments using a context manager.\n",
    "\n",
    "# Create a context manager for the experiment and is named 'risecamp_demo'\n",
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "\n",
    "    # Defines artifacts\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag='second')\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag='second')\n",
    "\n",
    "    #Define split action and resulting output artifacts\n",
    "    do_split = ex.action(traintest_split, [data_x, data_y])\n",
    "    X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "    X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "    y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "    y_test = ex.artifact('y_test.json', 'y_test', do_split)\n",
    "\n",
    "    #Define the hyperparameters for the models\n",
    "    random_forest_Nestimators = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "#     random_forest_Nestimators = ex.literalForEach(v=[5, 10, 15], name=\"hyperparameters\", default=5) #SOLUTION\n",
    "\n",
    "    #Define the model training and evaluation action and final artifacts\n",
    "    do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, random_forest_Nestimators])\n",
    "    report = ex.artifact('report.csv', 'report', do_test)\n",
    "    score = ex.literal(name='score', parent=do_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the experiment\n",
    "score.pull(utag=\"hyperparameter_tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Results\n",
    "\n",
    "After running the model with different hyperparameters above, we are able to peek at our output artifact, containing precision and recall metrics for the different models. Run the following cell - **which hyperparameter yields the best model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flor\n",
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Better Model\n",
    "\n",
    "Now that you have some experience using flor, let's try using a different model to see if we can improve the results. Some of the classifiers we recommend trying are the Multilayer Perceptron Classifier, Naive Bayes Classifier, and K-neighbors Classifier.\n",
    "\n",
    "After implementing your model of choice in the `train_test` function in **florfunctions.py**, run the cells below to reimport the function and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from florfunctions import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: We have copied the same experiment below for convenience.\n",
    "#We can also create flor experiments using a context manager.\n",
    "\n",
    "# Create a context manager for the experiment and is named 'risecamp_demo'\n",
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    # Defines artifacts\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag='first')\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag='first')\n",
    "\n",
    "    #Define split action and resulting output artifacts\n",
    "    do_split = ex.action(traintest_split, [data_x, data_y])\n",
    "    X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "    X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "    y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "    y_test = ex.artifact('y_test.json', 'y_test', do_split)\n",
    "\n",
    "    #Define the hyperparameters for the models\n",
    "    #hyperparameter = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "    random_forest_Nestimators = ex.literalForEach(v=[5, 10, 15], name=\"hyperparameters\", default=5) #SOLUTION\n",
    "    #MLP_hidden_layer_size = ex.literalForEach(v=[(1, ), (2, ), (3, )], name=\"hyperparameters\", default=(2, ))\n",
    "\n",
    "    #Define the model training and evaluation action and final artifacts\n",
    "    #change to MLP_hidden_layer_size \n",
    "    do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, random_forest_Nestimators])\n",
    "    #for naive bayes\n",
    "    #do_test = ex.action(train_test, [X_train, X_test, y_train, y_test])\n",
    "    report = ex.artifact('report.csv', 'report', do_test)\n",
    "    score = ex.literal(name='score', parent=do_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score.pull(utag=\"improved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Of all the things we tried, what helped the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.Experiment('risecamp_demo').summarize().cube()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
