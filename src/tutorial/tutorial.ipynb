{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flor\n",
    "\n",
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![object model](./object_model.png)\n",
    "<center><i>Artifacts in rectangles; Literals in underline; Actions in circles</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment before starting the activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by importing Flor and letting it know the name of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Flor\n",
    "import flor\n",
    "\n",
    "# If the notebook name has not already been set, you are able to set the name in code. \n",
    "flor.setNotebookName('tutorial.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analaysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll go through a short exercise to illustrate a common interactive model-training pattern. Here, we hope to demonstrate the value of versioning and provenance to motivate Flor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. We're going to train a model to predict the sentiment polarity (positive, or negative) of English phrases. The model-training pipeline is fairly standard: we load a dataset, do some light preprocessing, do a train/test split, train the model, and then validate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "movie_reviews = pd.read_json('data.json')\n",
    "\n",
    "# Do light preprocessing\n",
    "movie_reviews['rating'] = movie_reviews['rating'].map(lambda x: 0 if x < 5 else 1)\n",
    "\n",
    "# Do train/test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(movie_reviews['text'], movie_reviews['rating'], test_size=0.20, random_state=92)\n",
    "\n",
    "# Vectorize the English sentences\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_tr)\n",
    "X_tr = vectorizer.transform(X_tr)\n",
    "X_te = vectorizer.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.71      0.72      5024\n",
      "          1       0.71      0.73      0.72      4976\n",
      "\n",
      "avg / total       0.72      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the model              ##############\n",
    "clf = RandomForestClassifier(n_estimators=5).fit(X_tr, y_tr)\n",
    "                             ##############\n",
    "y_pred = clf.predict(X_te)\n",
    "\n",
    "# Validate the predictions\n",
    "c = classification_report(y_te, y_pred)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a report above. The precision and recall are hovering around 70%. We also noticed that the Random Forest classifier was trained on just **5 estimators**, let's see what happens if we **increase the number of estimators to 7**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73      5024\n",
      "          1       0.73      0.73      0.73      4976\n",
      "\n",
      "avg / total       0.73      0.73      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit a new model            ###############\n",
    "clf2 = RandomForestClassifier(n_estimators=7).fit(X_tr, y_tr)\n",
    "                             ###############\n",
    "y_pred = clf2.predict(X_te)\n",
    "\n",
    "# Validate the predictions\n",
    "score = clf2.score(X_te, y_te)\n",
    "c = classification_report(y_te, y_pred)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a minor improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise we just completed, we enforced some rudimentary forms of versioning and provenance. For versioning, rather than over-writing our model-fitting cell, we created a new cell, and rather than overwriting the `clf` variable, we created a new `clf2` variable. Moreover, if we save and version this notebook in a version control system such as Git, we might be able to restore the current version of this notebook, and fit a very similar model to the one we wanted. Given these practices, if we break something, we can rollback. As for provenance, the plaintext accompanying the cells (as well as the in-line comments) will allow a human to interpret causal effects: the only thing we changed was the number of estimators, and we changed the number of estimators from 5 to 7, which improved the quality metrics of the model. This human analyst would be able to answer questions such as, what data did you read, and where did you read it from? And, what model did you fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite some of these benefits, this rudimentary form of versioning and provenance tracking doesn't scale well. An analyst rushing to meet a deadline may over-write the same cell rather than make a copy, or forget to commit to Git after any change to the notebook: this would compromise our quality of versioning. Moreover, it's easy to see that as the complexity of the model-training pipeline increases from a few dozen lines of code to the thousands, and the model-training pipeline involves some distribution of code and data, and use of heterogeneous and complex infrastructure, manual human inspection of source code will be an inadequate substitute for a provenance management system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis in Flor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor is a context-first system for managing the pipeline development phase of the ML Lifecycle. Two of the many useful things Flor supports is automatic versioning of experiments and provenance tracking. We'll start by showing these two features of Flor, while emphasizing how little effort it takes to wrap a pre-existing pipeline (namely, the one we ran before) in Flor. Here, we hope to convince you that you would rather use Flor than implement versioning and provenance tracking yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[***LABEL: BEGIN LOOP*** Ignore this the first time you see it, jump here when told. Jump here once.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we've copied the model-training pipeline (with 5 estimators). We highlight the differences in-line using `###`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "@flor.func#########################\n",
    "def split_train_and_eval(**kwargs):\n",
    "###################################\n",
    "    import pandas as pd\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import classification_report\n",
    "    movie_reviews = pd.read_json('data.json')\n",
    "    movie_reviews['rating'] = movie_reviews['rating'].map(lambda x: 0 if x < 5 else 1)\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(movie_reviews['text'], movie_reviews['rating'], test_size=0.20, random_state=92)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(X_tr)\n",
    "    X_tr = vectorizer.transform(X_tr)\n",
    "    X_te = vectorizer.transform(X_te)\n",
    "    clf = RandomForestClassifier(n_estimators=7).fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = clf.predict(X_te)\n",
    "\n",
    "    score = clf.score(X_te, y_te)\n",
    "    c = classification_report(y_te, y_pred)\n",
    "\n",
    "    print(c)\n",
    "    \n",
    "    #######################\n",
    "    return {'score': score}\n",
    "    #######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to make 2 changes to wrap our model-training pipeline in Flor:\n",
    "1. Copy and paste the code into a decorated function\n",
    "2. Return the value we want Flor to track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we declare an experiment that uses our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "                                        ### OUR PIPELINE ###\n",
    "    do_split_train_and_eval = ex.action(split_train_and_eval)\n",
    "    score = ex.literal(name='score', parent=do_split_train_and_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"181pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 180.88 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 176.8847,-184 176.8847,4 -4,4\"/>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"114.9423,-180 57.9423,-180 57.9423,-144 114.9423,-144 114.9423,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.4423\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"86.4423\" cy=\"-90\" rx=\"86.3847\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.4423\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_train_and_eval</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M86.4423,-143.8314C86.4423,-136.131 86.4423,-126.9743 86.4423,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.9424,-118.4132 86.4423,-108.4133 82.9424,-118.4133 89.9424,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"113.4423,-36 59.4423,-36 59.4423,0 113.4423,0 113.4423,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"59.4423,0 113.4423,0 \"/>\n",
       "<text text-anchor=\"middle\" x=\"86.4423\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">score</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M86.4423,-71.8314C86.4423,-64.131 86.4423,-54.9743 86.4423,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.9424,-46.4132 86.4423,-36.4133 82.9424,-46.4133 89.9424,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8d4f93c2b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see the dataflow graph of the our `risecamp_demo` experiment. We read it as follows: the function `split_train_and_eval` defined in the tutorial artifact (`tutorial.ipynb`) is run to produce a `score` value. Despite its simplicity and coarse granularity, this is a provenance graph for the `score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've only defined the computation. Let's run the code to train the model and produce a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70      5024\n",
      "          1       0.70      0.70      0.70      4976\n",
      "\n",
      "avg / total       0.70      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN ME ONLY ONCE!\n",
    "score.pull('first_pull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Aside: We run the cell above only once because we are naming the execution, and we want each name to uniquely identify an execution.***  To run an experiment more than once, either change the name of the execution (the value passed to `pull()`) or clear the name (and a timestamp will be assigned). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to remember or inspect what we've tried in the past, we call the `summarize` method of a Flor experiment like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>score</th>\n",
       "      <th>tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first_pull</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>tutorial_140245882381424.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         utag   score                        tutorial\n",
       "0  first_pull  0.7006  tutorial_140245882381424.ipynb"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN ME ONLY ONCE!\n",
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, and as expected, we see that the score is hovering around 70%. But we also see that our Jupyter notebook was automatically versioned (see the cell in the `tutorial` columns), and all of the relevant artifacts were associated with the execution name `first_pull`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Important instructions*** Now, you will jump to **LABEL: BEGIN LOOP**, and modify the cell underneath that label. Change the number of estimators from 5 to 7 (Line 20). Re-run every cell (unless they explicitly tell you to RUN ONLY ONCE). Then come back here and run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74      5024\n",
      "          1       0.73      0.74      0.74      4976\n",
      "\n",
      "avg / total       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score.pull('second_pull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>score</th>\n",
       "      <th>tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second_pull</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>tutorial_140244902199424.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_pull</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>tutorial_140245882381424.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          utag   score                        tutorial\n",
       "0  second_pull  0.7378  tutorial_140244902199424.ipynb\n",
       "1   first_pull  0.7006  tutorial_140245882381424.ipynb"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should see that what would have been a destructive change without Flor (over-writing a cell and re-running it), is properly handled with Flor. Flor automatically preserves versions and tracks provenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting someone else's work in Flor\n",
    "\n",
    "In this next exercise, as in many \"real-world\" cases, you'll be joining an in-progress model development effort. Bob, a fellow member of your team, has already attempted two different data-preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below but notice that we are using a different experiment name (`bob_preproc` rather than `risecamp_demo`). Here, we are going to summarize someone else's past experiment versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>data_loc</th>\n",
       "      <th>intermediate_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second_preproc</td>\n",
       "      <td>preprocess_4489614728.py</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>data_112399744192.json</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_preproc</td>\n",
       "      <td>preprocess_111988784040.py</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>data_111988784768.json</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             utag                  preprocess                  intermediate_X  \\\n",
       "0  second_preproc    preprocess_4489614728.py  data_clean_X_112394722104.json   \n",
       "1   first_preproc  preprocess_111988784040.py  data_clean_X_111988783760.json   \n",
       "\n",
       "                 data_loc                  intermediate_y  \n",
       "0  data_112399744192.json  data_clean_y_112394719416.json  \n",
       "1  data_111988784768.json  data_clean_y_111988784208.json  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('bob_preproc').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the output. The first column, `utag`, lists the different versions of the experiment by name. We can see there are two past versions of the experiment `bob_preproc`: `first_preproc`, and `second_preproc`.  Now, let's pause for a second, run the next cell, and continue reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"232pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 231.50 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 227.5,-184 227.5,4 -4,4\"/>\n",
       "<!-- 3 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"106.5,-180 29.5,-180 29.5,-144 106.5,-144 106.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocess</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"112\" cy=\"-90\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocessing</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M79.1031,-143.8314C84.1438,-135.5829 90.2056,-125.6635 95.7449,-116.5992\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.8249,-118.2713 101.0529,-107.9134 92.8519,-114.6212 98.8249,-118.2713\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"189.5,-180 124.5,-180 124.5,-144 189.5,-144 189.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"157\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_loc</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.6446,-143.8314C140.4893,-135.5829 134.2897,-125.6635 128.6245,-116.5992\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.4639,-114.5384 123.1959,-107.9134 125.5279,-118.2484 131.4639,-114.5384\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"104,-36 0,-36 0,0 104,0 104,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_X</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M97.1685,-72.2022C90.0827,-63.6992 81.4648,-53.3577 73.6637,-43.9965\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.1683,-41.5347 67.0776,-36.0931 70.7907,-46.016 76.1683,-41.5347\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"223.5,-36 122.5,-36 122.5,0 223.5,0 223.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"173\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_y</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M127.0787,-72.2022C134.2826,-63.6992 143.0441,-53.3577 150.9752,-43.9965\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.8774,-45.9855 157.6711,-36.0931 148.5364,-41.4605 153.8774,-45.9855\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8d4f9a2d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('bob_preproc').plot('first_preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the structure of the dataflow graph. We see that there are four (4) artifacts: `preprocess`, `data_loc`, `intermediate_X`, and `intermediate_y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the structure of the dataflow graph, for the second version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"232pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 231.50 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 227.5,-184 227.5,4 -4,4\"/>\n",
       "<!-- 3 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"106.5,-180 29.5,-180 29.5,-144 106.5,-144 106.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"68\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocess</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"112\" cy=\"-90\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">preprocessing</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M79.1031,-143.8314C84.1438,-135.5829 90.2056,-125.6635 95.7449,-116.5992\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.8249,-118.2713 101.0529,-107.9134 92.8519,-114.6212 98.8249,-118.2713\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"189.5,-180 124.5,-180 124.5,-144 189.5,-144 189.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"157\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_loc</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.6446,-143.8314C140.4893,-135.5829 134.2897,-125.6635 128.6245,-116.5992\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.4639,-114.5384 123.1959,-107.9134 125.5279,-118.2484 131.4639,-114.5384\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"104,-36 0,-36 0,0 104,0 104,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"52\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_X</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M97.1685,-72.2022C90.0827,-63.6992 81.4648,-53.3577 73.6637,-43.9965\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.1683,-41.5347 67.0776,-36.0931 70.7907,-46.016 76.1683,-41.5347\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"223.5,-36 122.5,-36 122.5,0 223.5,0 223.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"173\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_y</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M127.0787,-72.2022C134.2826,-63.6992 143.0441,-53.3577 150.9752,-43.9965\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.8774,-45.9855 157.6711,-36.0931 148.5364,-41.4605 153.8774,-45.9855\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8d4f9a2908>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('bob_preproc').plot('second_preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both node-link diagrams look the same. This means that the structure of the different experiment versions is the same; however, it is very likely that the contents of the computation graph differ. To see where the difference is, we `diff` the two versions of Bob's experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE DIFF\n",
      "experiment_graph.pkl\n",
      "preprocess.py\n",
      "tutorial.ipynb\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flor.Experiment('bob_preproc').diff('first_preproc', 'second_preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `preprocess.py` was modified, so Bob probably tried two different preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue to audit Bob with Flor, and this would alone be an interesting and worthwhile activity, but for the purposes of this tutorial, we will start by _using_ the preprocessed data created by Bob, and inspect it only if we need to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using someone else's work in Flor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we brought ourselves \"up to speed\" with the preprocessing work that our colleague Bob had undertaken. We will now use Bob's preprocessed data instead of preprocessing the data ourselves. Here, we will show you how two different users of Flor may share their experiments and the artifacts/derived or consumed therewith."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a reminder of what the previous experiment versions look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>intermediate_y</th>\n",
       "      <th>data_loc</th>\n",
       "      <th>intermediate_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second_preproc</td>\n",
       "      <td>preprocess_4489614728.py</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_112399744192.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_preproc</td>\n",
       "      <td>preprocess_111988784040.py</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_111988784768.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             utag                  preprocess                  intermediate_y  \\\n",
       "0  second_preproc    preprocess_4489614728.py  data_clean_y_112394719416.json   \n",
       "1   first_preproc  preprocess_111988784040.py  data_clean_y_111988784208.json   \n",
       "\n",
       "                 data_loc                  intermediate_X  \n",
       "0  data_112399744192.json  data_clean_X_112394722104.json  \n",
       "1  data_111988784768.json  data_clean_X_111988783760.json  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('bob_preproc').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we copy/pasted the pipeline you're already familiar with. As before, we highlight the changes in `###`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flor.func              ##############  ##############  ############\n",
    "def split_train_and_eval(intermediate_X, intermediate_y, n_estimators, **kwargs):\n",
    "                        ##############  ##############  ############\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import classification_report\n",
    "            \n",
    "              ##############\n",
    "    with open(intermediate_X) as json_data:\n",
    "              ##############\n",
    "        X = json.load(json_data)\n",
    "        json_data.close()\n",
    "        \n",
    "              ##############\n",
    "    with open(intermediate_y) as json_data:\n",
    "              ##############\n",
    "        y = json.load(json_data)\n",
    "        json_data.close()\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, random_state=92)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(X_tr)\n",
    "    X_tr = vectorizer.transform(X_tr)\n",
    "    X_te = vectorizer.transform(X_te)\n",
    "    \n",
    "                                              ############\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators).fit(X_tr, y_tr)\n",
    "                                              ############\n",
    "    \n",
    "    y_pred = clf.predict(X_te)\n",
    "\n",
    "    score = clf.score(X_te, y_te)\n",
    "    print(score)\n",
    "    \n",
    "    return {'score': score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('bob_preproc') as ex:\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag=\"first_preproc\")\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag=\"first_preproc\")\n",
    "\n",
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    n_estimators = ex.literalForEach([5, 7], 'n_estimators')\n",
    "    do_split_train_and_eval = ex.action(split_train_and_eval, [data_x, data_y, n_estimators])\n",
    "    score = ex.literal(name='score', parent=do_split_train_and_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"414pt\" height=\"207pt\"\n",
       " viewBox=\"0.00 0.00 414.00 207.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 203)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 410,-203 410,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster2n_estimators</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"93.5,-8 93.5,-155 281.5,-155 281.5,-8 93.5,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-139.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2x</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"57,-199 0,-199 0,-163 57,-163 57,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"28.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"187.5\" cy=\"-106\" rx=\"86.3847\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_train_and_eval</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57.1307,-167.4301C60.2917,-165.9343 63.4637,-164.4343 66.5,-163 91.874,-151.0138 120.2562,-137.6419 143.1519,-126.8636\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"144.7235,-129.9922 152.2807,-122.5667 141.7423,-123.6588 144.7235,-129.9922\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"179.5,-199 75.5,-199 75.5,-163 179.5,-163 179.5,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_X</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.0243,-162.8446C149.4679,-153.5401 158.662,-142.0475 166.8309,-131.8364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.5955,-133.9834 173.1094,-123.9882 164.1294,-129.6105 169.5955,-133.9834\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"299,-199 198,-199 198,-163 299,-163 299,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_y</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.7336,-162.8446C226.1659,-153.5401 216.8187,-142.0475 208.5136,-131.8364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.1556,-129.5378 202.1304,-123.9882 205.725,-133.9547 211.1556,-129.5378\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"406,-199 317,-199 317,-163 406,-163 406,-199\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"317,-163 406,-163 \"/>\n",
       "<text text-anchor=\"middle\" x=\"361.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">n_estimators</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M319.3795,-162.8446C293.85,-151.8405 261.2206,-137.7761 234.8055,-126.3903\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.9481,-123.0716 225.3794,-122.3273 233.1773,-129.4998 235.9481,-123.0716\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"214.5,-52 160.5,-52 160.5,-16 214.5,-16 214.5,-52\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"160.5,-16 214.5,-16 \"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">score</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M187.5,-87.8314C187.5,-80.131 187.5,-70.9743 187.5,-62.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.0001,-62.4132 187.5,-52.4133 184.0001,-62.4133 191.0001,-62.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8d812c9dd8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6286\n",
      "0.6567\n"
     ]
    }
   ],
   "source": [
    "#Run the experiment\n",
    "score.pull('third_pull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>tutorial</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>intermediate_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>third_pull</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>7.0</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>third_pull</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second_pull</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_140244902199424.ipynb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first_pull</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_140245882381424.ipynb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          utag   score  n_estimators                        tutorial  \\\n",
       "0   third_pull  0.6567           7.0  tutorial_140244902200992.ipynb   \n",
       "1   third_pull  0.6286           5.0  tutorial_140244902200992.ipynb   \n",
       "2  second_pull  0.7378           NaN  tutorial_140244902199424.ipynb   \n",
       "3   first_pull  0.7006           NaN  tutorial_140245882381424.ipynb   \n",
       "\n",
       "                   intermediate_X                  intermediate_y  \n",
       "0  data_clean_X_111988783760.json  data_clean_y_111988784208.json  \n",
       "1  data_clean_X_111988783760.json  data_clean_y_111988784208.json  \n",
       "2                             NaN                             NaN  \n",
       "3                             NaN                             NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull again, trying a different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>data_loc</th>\n",
       "      <th>intermediate_y</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second_preproc</td>\n",
       "      <td>data_112399744192.json</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>preprocess_4489614728.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first_preproc</td>\n",
       "      <td>data_111988784768.json</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>preprocess_111988784040.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             utag                data_loc                  intermediate_y  \\\n",
       "0  second_preproc  data_112399744192.json  data_clean_y_112394719416.json   \n",
       "1   first_preproc  data_111988784768.json  data_clean_y_111988784208.json   \n",
       "\n",
       "                   intermediate_X                  preprocess  \n",
       "0  data_clean_X_112394722104.json    preprocess_4489614728.py  \n",
       "1  data_clean_X_111988783760.json  preprocess_111988784040.py  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('bob_preproc').summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.version = \"second_preproc\"\n",
    "data_y.version = \"second_preproc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"414pt\" height=\"207pt\"\n",
       " viewBox=\"0.00 0.00 414.00 207.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 203)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-203 410,-203 410,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster2n_estimators</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"93.5,-8 93.5,-155 281.5,-155 281.5,-8 93.5,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-139.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2x</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"57,-199 0,-199 0,-163 57,-163 57,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"28.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"187.5\" cy=\"-106\" rx=\"86.3847\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-102.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split_train_and_eval</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57.1307,-167.4301C60.2917,-165.9343 63.4637,-164.4343 66.5,-163 91.874,-151.0138 120.2562,-137.6419 143.1519,-126.8636\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"144.7235,-129.9922 152.2807,-122.5667 141.7423,-123.6588 144.7235,-129.9922\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"179.5,-199 75.5,-199 75.5,-163 179.5,-163 179.5,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_X</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.0243,-162.8446C149.4679,-153.5401 158.662,-142.0475 166.8309,-131.8364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.5955,-133.9834 173.1094,-123.9882 164.1294,-129.6105 169.5955,-133.9834\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"299,-199 198,-199 198,-163 299,-163 299,-199\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_y</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.7336,-162.8446C226.1659,-153.5401 216.8187,-142.0475 208.5136,-131.8364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.1556,-129.5378 202.1304,-123.9882 205.725,-133.9547 211.1556,-129.5378\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"406,-199 317,-199 317,-163 406,-163 406,-199\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"317,-163 406,-163 \"/>\n",
       "<text text-anchor=\"middle\" x=\"361.5\" y=\"-177.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">n_estimators</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M319.3795,-162.8446C293.85,-151.8405 261.2206,-137.7761 234.8055,-126.3903\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.9481,-123.0716 225.3794,-122.3273 233.1773,-129.4998 235.9481,-123.0716\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"214.5,-52 160.5,-52 160.5,-16 214.5,-16 214.5,-52\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"160.5,-16 214.5,-16 \"/>\n",
       "<text text-anchor=\"middle\" x=\"187.5\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">score</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M187.5,-87.8314C187.5,-80.131 187.5,-70.9743 187.5,-62.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.0001,-62.4132 187.5,-52.4133 184.0001,-62.4133 191.0001,-62.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8d50384eb8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7255\n",
      "0.7515\n"
     ]
    }
   ],
   "source": [
    "score.pull('fourth_pull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>tutorial</th>\n",
       "      <th>intermediate_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>7.0</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>third_pull</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>7.0</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>third_pull</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>second_pull</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_140244902199424.ipynb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>first_pull</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_140245882381424.ipynb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          utag   score  n_estimators                  intermediate_X  \\\n",
       "0  fourth_pull  0.7515           7.0  data_clean_X_112394722104.json   \n",
       "1  fourth_pull  0.7255           5.0  data_clean_X_112394722104.json   \n",
       "2   third_pull  0.6567           7.0  data_clean_X_111988783760.json   \n",
       "3   third_pull  0.6286           5.0  data_clean_X_111988783760.json   \n",
       "4  second_pull  0.7378           NaN                             NaN   \n",
       "5   first_pull  0.7006           NaN                             NaN   \n",
       "\n",
       "                         tutorial                  intermediate_y  \n",
       "0  tutorial_140244902619568.ipynb  data_clean_y_112394719416.json  \n",
       "1  tutorial_140244902619568.ipynb  data_clean_y_112394719416.json  \n",
       "2  tutorial_140244902200992.ipynb  data_clean_y_111988784208.json  \n",
       "3  tutorial_140244902200992.ipynb  data_clean_y_111988784208.json  \n",
       "4  tutorial_140244902199424.ipynb                             NaN  \n",
       "5  tutorial_140245882381424.ipynb                             NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Of all the things we tried, what helped the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utag</th>\n",
       "      <th>score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>intermediate_y</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>7.0</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>third_pull</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>7.0</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>third_pull</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>second_pull</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_140244902199424.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>first_pull</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_140245882381424.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          utag   score  n_estimators                  intermediate_y  \\\n",
       "0  fourth_pull  0.7515           7.0  data_clean_y_112394719416.json   \n",
       "1  fourth_pull  0.7255           5.0  data_clean_y_112394719416.json   \n",
       "2   third_pull  0.6567           7.0  data_clean_y_111988784208.json   \n",
       "3   third_pull  0.6286           5.0  data_clean_y_111988784208.json   \n",
       "4  second_pull  0.7378           NaN                             NaN   \n",
       "5   first_pull  0.7006           NaN                             NaN   \n",
       "\n",
       "                   intermediate_X                        tutorial  \n",
       "0  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "1  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "2  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "3  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "4                             NaN  tutorial_140244902199424.ipynb  \n",
       "5                             NaN  tutorial_140245882381424.ipynb  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = flor.Experiment('risecamp_demo').summarize()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>utag</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>intermediate_y</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.70060</td>\n",
       "      <td>first_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140245882381424.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.73780</td>\n",
       "      <td>second_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902199424.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>ALL</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.73850</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.64265</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>ALL</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.72550</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.75150</td>\n",
       "      <td>fourth_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>tutorial_140244902619568.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.62860</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>5</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.65670</td>\n",
       "      <td>third_pull</td>\n",
       "      <td>7</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>tutorial_140244902200992.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score         utag n_estimators                  intermediate_y  \\\n",
       "0   0.72550  fourth_pull            5                             ALL   \n",
       "1   0.75150  fourth_pull            7                             ALL   \n",
       "2   0.62860   third_pull            5                             ALL   \n",
       "3   0.65670   third_pull            7                             ALL   \n",
       "4   0.73850  fourth_pull          ALL  data_clean_y_112394719416.json   \n",
       "5   0.64265   third_pull          ALL  data_clean_y_111988784208.json   \n",
       "6   0.73850  fourth_pull          ALL                             ALL   \n",
       "7   0.64265   third_pull          ALL                             ALL   \n",
       "8   0.70060   first_pull          ALL                             ALL   \n",
       "9   0.73850  fourth_pull          ALL                             ALL   \n",
       "10  0.73780  second_pull          ALL                             ALL   \n",
       "11  0.64265   third_pull          ALL                             ALL   \n",
       "12  0.72550  fourth_pull            5  data_clean_y_112394719416.json   \n",
       "13  0.75150  fourth_pull            7  data_clean_y_112394719416.json   \n",
       "14  0.62860   third_pull            5  data_clean_y_111988784208.json   \n",
       "15  0.65670   third_pull            7  data_clean_y_111988784208.json   \n",
       "16  0.72550  fourth_pull            5                             ALL   \n",
       "17  0.75150  fourth_pull            7                             ALL   \n",
       "18  0.62860   third_pull            5                             ALL   \n",
       "19  0.65670   third_pull            7                             ALL   \n",
       "20  0.72550  fourth_pull            5                             ALL   \n",
       "21  0.75150  fourth_pull            7                             ALL   \n",
       "22  0.62860   third_pull            5                             ALL   \n",
       "23  0.65670   third_pull            7                             ALL   \n",
       "24  0.73850  fourth_pull          ALL  data_clean_y_112394719416.json   \n",
       "25  0.64265   third_pull          ALL  data_clean_y_111988784208.json   \n",
       "26  0.73850  fourth_pull          ALL  data_clean_y_112394719416.json   \n",
       "27  0.64265   third_pull          ALL  data_clean_y_111988784208.json   \n",
       "28  0.73850  fourth_pull          ALL                             ALL   \n",
       "29  0.64265   third_pull          ALL                             ALL   \n",
       "30  0.72550  fourth_pull            5  data_clean_y_112394719416.json   \n",
       "31  0.75150  fourth_pull            7  data_clean_y_112394719416.json   \n",
       "32  0.62860   third_pull            5  data_clean_y_111988784208.json   \n",
       "33  0.65670   third_pull            7  data_clean_y_111988784208.json   \n",
       "34  0.72550  fourth_pull            5  data_clean_y_112394719416.json   \n",
       "35  0.75150  fourth_pull            7  data_clean_y_112394719416.json   \n",
       "36  0.62860   third_pull            5  data_clean_y_111988784208.json   \n",
       "37  0.65670   third_pull            7  data_clean_y_111988784208.json   \n",
       "38  0.72550  fourth_pull            5                             ALL   \n",
       "39  0.75150  fourth_pull            7                             ALL   \n",
       "40  0.62860   third_pull            5                             ALL   \n",
       "41  0.65670   third_pull            7                             ALL   \n",
       "42  0.73850  fourth_pull          ALL  data_clean_y_112394719416.json   \n",
       "43  0.64265   third_pull          ALL  data_clean_y_111988784208.json   \n",
       "44  0.72550  fourth_pull            5  data_clean_y_112394719416.json   \n",
       "45  0.75150  fourth_pull            7  data_clean_y_112394719416.json   \n",
       "46  0.62860   third_pull            5  data_clean_y_111988784208.json   \n",
       "47  0.65670   third_pull            7  data_clean_y_111988784208.json   \n",
       "\n",
       "                    intermediate_X                        tutorial  \n",
       "0                              ALL                             ALL  \n",
       "1                              ALL                             ALL  \n",
       "2                              ALL                             ALL  \n",
       "3                              ALL                             ALL  \n",
       "4                              ALL                             ALL  \n",
       "5                              ALL                             ALL  \n",
       "6   data_clean_X_112394722104.json                             ALL  \n",
       "7   data_clean_X_111988783760.json                             ALL  \n",
       "8                              ALL  tutorial_140245882381424.ipynb  \n",
       "9                              ALL  tutorial_140244902619568.ipynb  \n",
       "10                             ALL  tutorial_140244902199424.ipynb  \n",
       "11                             ALL  tutorial_140244902200992.ipynb  \n",
       "12                             ALL                             ALL  \n",
       "13                             ALL                             ALL  \n",
       "14                             ALL                             ALL  \n",
       "15                             ALL                             ALL  \n",
       "16  data_clean_X_112394722104.json                             ALL  \n",
       "17  data_clean_X_112394722104.json                             ALL  \n",
       "18  data_clean_X_111988783760.json                             ALL  \n",
       "19  data_clean_X_111988783760.json                             ALL  \n",
       "20                             ALL  tutorial_140244902619568.ipynb  \n",
       "21                             ALL  tutorial_140244902619568.ipynb  \n",
       "22                             ALL  tutorial_140244902200992.ipynb  \n",
       "23                             ALL  tutorial_140244902200992.ipynb  \n",
       "24  data_clean_X_112394722104.json                             ALL  \n",
       "25  data_clean_X_111988783760.json                             ALL  \n",
       "26                             ALL  tutorial_140244902619568.ipynb  \n",
       "27                             ALL  tutorial_140244902200992.ipynb  \n",
       "28  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "29  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "30  data_clean_X_112394722104.json                             ALL  \n",
       "31  data_clean_X_112394722104.json                             ALL  \n",
       "32  data_clean_X_111988783760.json                             ALL  \n",
       "33  data_clean_X_111988783760.json                             ALL  \n",
       "34                             ALL  tutorial_140244902619568.ipynb  \n",
       "35                             ALL  tutorial_140244902619568.ipynb  \n",
       "36                             ALL  tutorial_140244902200992.ipynb  \n",
       "37                             ALL  tutorial_140244902200992.ipynb  \n",
       "38  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "39  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "40  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "41  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "42  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "43  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "44  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "45  data_clean_X_112394722104.json  tutorial_140244902619568.ipynb  \n",
       "46  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  \n",
       "47  data_clean_X_111988783760.json  tutorial_140244902200992.ipynb  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.cube({'score': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
