{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Sharing and Composition\n",
    "\n",
    "In this part, we're going to show you (a) how to interpret a Flor experiment that someone else has shared with you, and (b) how you can re-use the artifacts of someone else's experiment in your own experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment before starting the activities.\n",
    "\n",
    "We're going to start by importing Flor and letting it know the name of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Flor\n",
    "import flor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# If the notebook name has not already been set, you are able to set the name in code. \n",
    "flor.setNotebookName('tutorial_2.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting someone else's work in Flor\n",
    "\n",
    "In this next exercise, as in many \"real-world\" cases, you'll be joining an in-progress model development effort. Bob, a fellow member of your team, has already attempted two different data-preprocessing steps.\n",
    "\n",
    "Run the cell below but notice that we are using a different experiment name (`bob_preproc` rather than `risecamp_demo`). Here, we are going to summarize someone else's past experiment versions.\n",
    "\n",
    "**HOW DO WE KNOW ABOUT THIS EXPERIMENT bob_preproc? (Bob told us its name??)  HOW WAS IT GENERATED, AND WHERE WAS THE METADATA ABOUT THIS EXPERIMENT STORED? (Bob's version of Flor was connected to the same Ground server? Ran in the same directory?? Make this not magic!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret the output. The first column, `label`, lists the different versions of the experiment by name. We can see there are two past versions of the experiment `bob_preproc`: `first_preproc`, and `second_preproc`.  Now, let's pause for a second, run the next cell, and continue reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').plot('first_preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the structure of the Flor Plan for Bob's preprocessing expriment. We see that there are four (4) rectangles: \n",
    "* Inputs: `preprocess`, `data_loc`\n",
    "* Outputs: `intermediate_X`, and `intermediate_y`.\n",
    "\n",
    "Notice how the names in the Flor Plan correspond to the names in the columns of the Summary Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the structure of the dataflow graph for the second version of Bob's experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').plot('second_preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both node-link diagrams look the same. This means that the structure of the different experiment versions is the same; however, it is very likely that the contents of the computation graph differ. To see where the difference is, we `diff` the two versions of Bob's experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').diff('first_preproc', 'second_preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `preprocess.py` was modified, so Bob probably tried two different preprocessing techniques. We see that `tutorial.ipynb` changed, probably because Bob ran a cell another time and that is enough to change a Jupyter notebook. Finally, you can see that a file called `experiment_graph.pkl` changed; this is internal information for Flor that we can ignore for now.\n",
    "\n",
    "If we want to inspect the differences in more detail, we can do so by controlling the flags to `diff`. Below we add the flag **GIVE THEM ONE FLAG TO HIGHLIGHT THE POINT, AND FINISH THIS SENTENCE**. (Flor's Experiment diff wraps a call to `git diff`, so you're welcome to try any `git diff` flags you're familiar with to compare the experiment versions.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').diff('first_preproc', 'second_preproc', flags=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've used Flor to learn a bit about the preprocessing pipeline we inherited from Bob. Now let's start _using_ the preprocessed data he created; we'll inspect the preprocessing pipeline more deeply if/when we need to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using someone else's work in Flor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen how we can \"inherit\" a Flor experiment, we will now see how two different users of Flor can share their experiments and the artifactsthat they derive or consume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a reminder of what the previous experiment versions look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `tutorial_1.ipynb`, we called `flor.track_action` to wrap a pipeline and execute it with a minimum of extra Flor wrapper code. Although that minimalist use of Flor for wrapping pipelines is convenient, it has limited expressivity. In the next cell, we introduce more expressive Flor syntax that is able to represent pipelines with many actions, and enables us to re-use the artifacts of someone else's experiment. This will require a bit more Flor annotation than our previous example, but it will also give us more detailed information.\n",
    "\n",
    "Below, we copy/pasted the pipeline you worked on in `tutorial_1.ipynb`. We made the following changes: \n",
    "1. We switched from the concise to the expressive Flor syntax. Notice the first lines: we use the `flor.func` decorator rather than `flor.track_action`.\n",
    "2. Rather than preprocessing data ourselves, we pass in Bob's `intermediate_X` and `intermediate_y` artifacts\n",
    "\n",
    "As before, we highlight the changes in `###`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########\n",
    "@flor.func\n",
    "##########               ##############  ##############\n",
    "def split_train_and_eval(intermediate_X, intermediate_y, n_estimators, max_depth, **kwargs):\n",
    "                         ##############  ##############\n",
    "    import pandas as pd\n",
    "    import json\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import classification_report\n",
    "            \n",
    "              ##############\n",
    "    with open(intermediate_X) as json_data:\n",
    "              ##############\n",
    "        X = json.load(json_data)\n",
    "        json_data.close()\n",
    "        \n",
    "              ##############\n",
    "    with open(intermediate_y) as json_data:\n",
    "              ##############\n",
    "        y = json.load(json_data)\n",
    "        json_data.close()\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, random_state=92)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(X_tr)\n",
    "    X_tr = vectorizer.transform(X_tr)\n",
    "    X_te = vectorizer.transform(X_te)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth).fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = clf.predict(X_te)\n",
    "\n",
    "    score = clf.score(X_te, y_te)\n",
    "    print(score)\n",
    "    \n",
    "    return {'score': score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, notice that unlike in `tutorial_1.ipynb`, running the cell above did not execute the experiment. That's because so far we've only told Flor to track this code, but we have yet to specify where this code fits in the overall Flor Plan (computation graph). We specify the Flor Plan below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c8349679634f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mflor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bob_preproc'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'risecamp_demo'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# This is how we tell Flor we will be using Bob's derived artifacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_clean_X.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'intermediate_X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first_preproc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_clean_y.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'intermediate_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first_preproc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flor' is not defined"
     ]
    }
   ],
   "source": [
    "with flor.Experiment('bob_preproc') as bob, flor.Experiment('risecamp_demo') as ex:\n",
    "    # This is how we tell Flor we will be using Bob's derived artifacts\n",
    "    data_x = bob.artifact('data_clean_X.json', 'intermediate_X', label=\"first_preproc\")\n",
    "    data_y = bob.artifact('data_clean_y.json', 'intermediate_y', label=\"first_preproc\")\n",
    "    \n",
    "    # This is how we specify the \"literals\" (parameters) of the Flor Plan for our experiments     \n",
    "    n_estimators = ex.literal(7, 'n_estimators') # We pick the best number of estimators from the previous notebook\n",
    "    max_depth = ex.literal(100, 'max_depth') # We pick the best max depth from the previous notebook\n",
    "                                                                \n",
    "    # This is where we put the code we declared in the cell above-\n",
    "    #               And this is how we pass in Bob's artifacts ---|-------|\n",
    "    #                                                          ---v-------v\n",
    "    do_split_train_and_eval = ex.action(split_train_and_eval, [data_x, data_y, n_estimators, max_depth])\n",
    "    score = ex.literal(name='score', parent=do_split_train_and_eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we've declared the code, declared the artifacts, and specified the Flor Plan of our experiment. We are now ready to run it, but first, let's make sure we built the graph we intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph looks as it should. Notice how we are now consuming Bob's `Intermediate_X` and `Intermediate_y` artifacts in our experiment. Although the expressive Flor syntax involves the additional work of specifying the Flor Plan, this freedom allows us to track more context, and share artifacts across experiments.\n",
    "\n",
    "Next, we run the experiment we've specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.pull('fifth_pull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we summarize our `risecamp_demo` experiment, we can see all of the executions from `tutorial_1.ipynb` plus the new execution we just finished (`fifth_pull`). Interestingly, we see that despite using the best configuration from `tutorial_1.ipynb`: `n_estimators=7.0` and `max_depth=100`, our score dropped to around 65%.\n",
    "\n",
    "The only thing we did differently was to use Bob's preprocessed data rather than preprocess our own data. We used the first version of Bob's preprocessed data, but there were two versions. Let's see whether the second and latest version performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrying the same experiment, but changing to Bob's latest version of the data\n",
    "As before, let's start by looking at the summary of Bob's past experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('bob_preproc').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already tried label `first_preproc` , so let's try `second_preproc` this time. We already specified the Flor Plan above, and we are satisfied with the plan, we just want to update the version of the data. We do so as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x.version = \"second_preproc\"\n",
    "data_y.version = \"second_preproc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot to make sure the plan didn't change structurally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Flor Plan didn't change, so we execute a new version of our experiment, using Bob's latest version of the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.pull('sixth_pull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the results one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that our score is the highest yet, so it was a good idea to switch to Bob's latest version of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your pipeline in Flor helps others interpret your work, and re-use artifacts you derived, such as code or data.\n",
    "**IF WE'RE GOING TO PUT \"Key Takeaways\" AT THE BOTTOM HERE, WE SHOULD DO SO FOR THE OTHER 2 NOTEBOOKs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you! You may now move on to `tutorial_3.ipynb`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
