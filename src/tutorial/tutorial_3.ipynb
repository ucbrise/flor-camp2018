{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Finer-Grained Annotating and Versioning\n",
    "\n",
    "Now that we've learned how to use the expressive syntax of Flor, we will annotate and version the experiment we have been developing in as much detail as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment before starting the activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by importing Flor and letting it know the name of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Flor\n",
    "import flor\n",
    "\n",
    "# If the notebook name has not already been set, you are able to set the name in code. \n",
    "flor.setNotebookName('tutorial_3.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll declare all our code in advance\n",
    "\n",
    "The first thing we'll do is split the data. For now, pay attention to how Flor reads and writes data. We'll later tell Flow what an input is and what an output is when we're specifying the Flor Plan. Also, notice how in the past, the resulting training/testing split (and the parameters) were lost, but we're able to track them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def split(intermediate_X, intermediate_y, test_size, random_state, \n",
    "          X_train, X_test, y_train, y_test, **kwargs):\n",
    "    import json\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Read the inputs\n",
    "    with open(intermediate_X) as json_data:\n",
    "        X = json.load(json_data)\n",
    "        json_data.close()\n",
    "        \n",
    "    with open(intermediate_y) as json_data:\n",
    "        y = json.load(json_data)\n",
    "        json_data.close()\n",
    "        \n",
    "    # Split the data\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Write the outputs\n",
    "    with open(X_train, 'w') as f:\n",
    "        json.dump(X_tr, f)\n",
    "    with open(X_test, 'w') as f:\n",
    "        json.dump(X_te, f)\n",
    "    with open(y_train, 'w') as f:\n",
    "        json.dump(y_tr, f)\n",
    "    with open(y_test, 'w') as f:\n",
    "        json.dump(y_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see how the output of `split`: `X_train` and `y_train` might be passed in as input to `train`. We're also going to serialize the model and vectorizer so we can retrieve them in the future rather than have to re-run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def train(X_train, y_train, n_estimators, max_depth, model, vectorizer, **kwargs):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import cloudpickle\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Read the inputs\n",
    "    with open(X_train, 'r') as f:\n",
    "        X_tr = json.load(f)\n",
    "    with open(y_train, 'r') as f:\n",
    "        y_tr = json.load(f)\n",
    "    \n",
    "    # Fit the vectorizer\n",
    "    vec = TfidfVectorizer()\n",
    "    vec.fit(X_tr)\n",
    "    \n",
    "    # Transform the training data\n",
    "    X_tr = vec.transform(X_tr)\n",
    "    \n",
    "    # Train the model\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth).fit(X_tr, y_tr)\n",
    "    \n",
    "    # Write the output\n",
    "    with open(model, 'wb') as f:\n",
    "        cloudpickle.dump(clf, f)\n",
    "    with open(vectorizer, 'wb') as f:\n",
    "        cloudpickle.dump(vec, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll take the test data, model, and vectorizer to evaluate the model we just trained. We're also going to return the score to facilitate interpretation of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def eval(X_test, y_test, model, vectorizer, **kwargs):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import cloudpickle\n",
    "    \n",
    "    # Read the inputs\n",
    "    with open(X_test, 'r') as f:\n",
    "        X_te = json.load(f)\n",
    "    with open(y_test, 'r') as f:\n",
    "        y_te = json.load(f)\n",
    "    with open(model, 'rb') as f:\n",
    "        clf = cloudpickle.load(f)\n",
    "    with open(vectorizer, 'rb') as f:\n",
    "        vec = cloudpickle.load(f)\n",
    "    \n",
    "    # Test the model\n",
    "    X_te = vec.transform(X_te)\n",
    "    score = clf.score(X_te, y_te)\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    # Return the score\n",
    "    return {'score': score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll build a detailed Flor Plan, exposing all hyper-parameters and intermediary artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've declared the code, and know which resources to read (Bob's latest preprocessed data), we can specify the Flor Plan. Pay close attention to how we indicate the outputs of an action, and how we pass the output of some action to another action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('bob_preproc') as bob, flor.Experiment('risecamp_demo') as ex:\n",
    "    # This is how we tell Flor we will be using Bob's derived artifacts\n",
    "    data_x = bob.artifact('data_clean_X.json', 'intermediate_X', label=\"second_preproc\")\n",
    "    data_y = bob.artifact('data_clean_y.json', 'intermediate_y', label=\"second_preproc\")\n",
    "    \n",
    "    # Here we declare all the static literals\n",
    "    random_state = ex.literal(92, 'random_state')\n",
    "    test_size = ex.literal(0.20, 'test_size')\n",
    "    n_estimators = ex.literal(7, 'n_estimators') \n",
    "    max_depth = ex.literal(100, 'max_depth')\n",
    "    \n",
    "    # Now we connect the Flor Plan\n",
    "    do_split = ex.action(func=split, in_artifacts=[data_x, data_y, test_size, random_state])\n",
    "    X_train = ex.artifact(loc='X_train.json', name='X_train', parent=do_split)\n",
    "    X_test = ex.artifact(loc='X_test.json', name='X_test', parent=do_split)\n",
    "    y_train = ex.artifact(loc='y_train.json', name='y_train', parent=do_split)\n",
    "    y_test = ex.artifact(loc='y_test.json', name='y_test', parent=do_split)\n",
    "    \n",
    "    do_train = ex.action(func=train, in_artifacts=[X_train, y_train, n_estimators, max_depth])\n",
    "    model = ex.artifact(loc='model.pkl', name='model', parent=do_train)\n",
    "    vectorizer = ex.artifact(loc='vectorizer.pkl', name='vectorizer', parent=do_train)\n",
    "    \n",
    "    do_eval = ex.action(func=eval, in_artifacts=[X_test, y_test, model, vectorizer])\n",
    "    score = ex.literal(name='score', parent=do_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've only seen Flor Plans with a single action, this is what a detailed Flor Plan for our experiment looks like. The rectangles correspond to artifacts, which the user is responsible for reading/writing, but Flor automatically tracks and versions. The underlines correspond to literals, which Flor manages completely and manages them by value. As a rule of thumb, if it can be serialized as a string without losing information, then it can be a literal. Otherwise, it's best to represent it as an artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pull the score to execute the experiment we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.pull('seventh_pull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the score is still hovering around 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the benefits of the finer-grained annotations. Compared to the very first experiment we ran, this experiment is easier to interpret without having to read code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Because we now track intermediary artifacts, such as the model, it is no longer necessary to re-run an experiment and train the model, instead we can just retrieve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout best model and serve it\n",
    "Here, we're going to retrieve the model and vectorizer we just fitted with Flor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    model = ex.artifact('model.pkl', 'model', label='seventh_pull')\n",
    "    vectorizer = ex.artifact('vectorizer.pkl', 'vectorizer', label='seventh_pull')\n",
    "model = model.peek()\n",
    "vec = vectorizer.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deploy the model into a toy application that tries to predict the sentiment from your phrases. Enter `nothing` to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"What's on your mind? \"\n",
    "\n",
    "phrase = input(PROMPT)\n",
    "while phrase[0:len('nothing')].lower() != 'nothing':\n",
    "    phrase = vec.transform([phrase,])\n",
    "    positive = model.predict(phrase)\n",
    "    if positive:\n",
    "        print('Happy to hear that!\\n'.format(phrase))\n",
    "    else:\n",
    "        print(\"Sorry about that...\\n\")\n",
    "    phrase = input(PROMPT)\n",
    "print('you said nothing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, we've been reminded of the value of annotating and versioning experiments, and witnessed how Flor can automate these responsibilities with as few as 3 lines of code. Moreover, when finer-grained tracking is desired, Flor is able to capture more meta-data and store derived artifacts for future retrieval. Flor enables experiment interpretation and re-using artifacts across experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for your time, we hope you have a good evening."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
