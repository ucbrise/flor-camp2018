{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import stop_words\n",
    "import util\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  For a movie that gets no respect there sure ar...      9\n",
       "1  Bizarre horror movie filled with famous faces ...      8\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...      7\n",
       "3  It's a strange feeling to sit alone in a theat...      8\n",
       "4  You probably all already know this by now, but...     10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['rating'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "en_stop = get_stop_words('en')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "def filter_sentence(el):\n",
    "    tokens = word_tokenize(el)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in en_stop]\n",
    "    stems = stem_words(tokens)\n",
    "    lemmas = lemma_words(stems)\n",
    "    \n",
    "    ret_str = \" \".join(lemmas) \n",
    "    \n",
    "    return ret_str \n",
    "\n",
    "\n",
    "#https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html\n",
    "def stem_words(words):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemma_words(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "X = [filter_sentence(el) for el in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = []\n",
    "for el in y:\n",
    "    ret = 0\n",
    "    if el <= 3:\n",
    "        ret = 0\n",
    "    elif el >= 4 and el <= 6:\n",
    "        ret = 1\n",
    "    else:\n",
    "        ret = 2\n",
    "    y_new.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (50000, 66911)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "print('Shape of Sparse Matrix: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2841    0 1057]\n",
      " [ 450    0  639]\n",
      " [ 240    0 4773]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.73      0.76      3898\n",
      "          1       0.00      0.00      0.00      1089\n",
      "          2       0.74      0.95      0.83      5013\n",
      "\n",
      "avg / total       0.68      0.76      0.71     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.20, random_state=92)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2954    0  944]\n",
      " [ 531   15  543]\n",
      " [ 375    0 4638]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.76      0.76      3898\n",
      "          1       1.00      0.01      0.03      1089\n",
      "          2       0.76      0.93      0.83      5013\n",
      "\n",
      "avg / total       0.79      0.76      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.20, random_state=92)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1924  519  425]\n",
      " [ 781 1237 1085]\n",
      " [ 239  544 3246]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.67      0.66      2868\n",
      "          1       0.54      0.40      0.46      3103\n",
      "          2       0.68      0.81      0.74      4029\n",
      "\n",
      "avg / total       0.63      0.64      0.63     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_new = TruncatedSVD(n_components=50).fit_transform(X)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.20, random_state=92)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT USE ANYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'gets', 'respect', 'sure', 'lot', 'memorable', 'quotes', 'listed', 'gem', 'Imagine', 'movie', 'Joe', 'Piscopo', 'actually', 'funny', 'Maureen', 'Stapleton', 'scene', 'stealer', 'Moroni', 'character', 'absolute', 'scream', 'Watch', 'Alan', 'Skipper', 'Hale', 'jr', 'police', 'Sgt']\n",
      "For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.\n"
     ]
    }
   ],
   "source": [
    "#TODO:\n",
    "#1) Stemming \n",
    "#2) Lemmization\n",
    "#3) Change output space to categories (pos, neutral, neg)\n",
    "#4) Evaluate model as a classification \n",
    "\n",
    "import string\n",
    "en_stop = get_stop_words('en') #FIXME: No is considered a stop word\n",
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in en_stop]\n",
    "print(text_process(X[0]))\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214905\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(X)\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (50000, 214905)\n"
     ]
    }
   ],
   "source": [
    "X = bow_transformer.transform(X)\n",
    "print('Shape of Sparse Matrix: ', X.shape)\n",
    "X = TruncatedSVD(n_components=50).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (50000, 500)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', X.shape)\n",
    "#print('Amount of Non-Zero occurences: ', X.nnz)\n",
    "#density = (100.0 * X.nnz / (X.shape[0] * X.shape[1]))\n",
    "#print('density: {}'.format((density)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.912956710655954\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=50).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_stop = get_stop_words('en')\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# p_stemmer = PorterStemmer()\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(data['text'])\n",
    "# X = TruncatedSVD(n_components=50).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.19288695, -0.05305406, -0.66116401, ...,  0.10113894,\n",
       "         0.33951692,  0.41442783],\n",
       "       [11.59245027, -3.23250713, -0.11666337, ..., -0.25401356,\n",
       "         0.39181239,  1.31366485],\n",
       "       [ 6.51584894, -1.85851634,  0.03288393, ..., -0.62419326,\n",
       "        -0.28197579,  0.17419579],\n",
       "       ...,\n",
       "       [32.58961625,  0.23972314, -0.59841473, ...,  0.29780136,\n",
       "        -0.78280033,  0.86414643],\n",
       "       [23.1264474 ,  1.12994973, -2.75848689, ..., -0.91031717,\n",
       "         0.22480928, -0.09767869],\n",
       "       [ 2.69147608, -0.26845077, -0.35913667, ...,  0.52262555,\n",
       "        -0.03752499,  0.26628965]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#y = min_max_scaler.fit_transform([data['rating']])\n",
    "#y = data['rating']\n",
    "#df = df/df.max().astype(np.float64)\n",
    "#y = y/y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1077622710454116\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=15).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = SVR(kernel='rbf').fit(X_train, y_train)\n",
    "#y_pred = clf.predict(X_test)\n",
    "#np.sqrt(mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
