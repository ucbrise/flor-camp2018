{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISE Camp 2018: Introduction to Flor!\n",
    "\n",
    "\n",
    "Welcome to RISE Camp 2018! Flor is a system for managing workflow development within the machine learning lifecycle. This tool enables data scientists to describe ML workflows as directed acyclic graphs (DAGs) of Actions, Artifacts, or Literals and to experiment with different configurations quickly by running multi-trial experiments. \n",
    "\n",
    "The purpose of this notebook is to help you use Flor in order to naviagte through different parts of the data science lifecycle.\n",
    "\n",
    "As you work through this notebook, you will learn:\n",
    "\n",
    "* How to define/use experiments, literals, artifacts and actions.\n",
    "* How to run experiments with different congigurations.\n",
    "* Compare models with other past versions in order to select the best model.\n",
    "\n",
    "We will be working with a ratings dataset. Our goal is to predict whether a movie review is positive or negative based on its text.\n",
    "\n",
    "**Data science is a collaborative activity - we encourage you to work with those around you and ask questions!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/rise/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import scipy.sparse\n",
    "import flor\n",
    "\n",
    "#Pre-processing imports\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#Model training and testing imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the notebook name has not already been set, you are able to set the name in code. \n",
    "flor.setNotebookName('tutorial.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Before building our model, we will define a pipeline to pre-process our text data. We have used the following techniques to pre-process the text reviews:\n",
    "* Removal of Stop Words\n",
    "* Stemming (reducing inflected words to their stem)\n",
    "* Lemmatization (group together inflected forms of a words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me\n",
    "from florfunctions import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "We have created a function to split our data into train/test sets. Since we would like this to be a Flor Function, we must wrap it with the @flor.func decorator so it is able to be referenced by Flor actions. **Please navigate to the florfunctions.py file and wrap the `traintest_split` function with the Flor decorator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me\n",
    "from florfunctions import traintest_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "Now, we can create a Flor function to train and evaluate a model to classify reviews into rating buckets. **Please navigate to the florfunctions.py file and complete the `train_test` function; fill in the Random Forest model with an n_estimators parameter of 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from florfunctions import train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup\n",
    "\n",
    "Finally, we will now define our Flor experiment using the Flor functions we created above. Proceed through the following cells and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = flor.Experiment('risecamp_demo').__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flor uses either **ground-context** or **grit** as data context services. Today, we will be using grit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.groundClient('git') #'git' for grit, 'ground' for ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the data we want to analyze. We can load the data by creating **artifacts**, which are pointers to data we want. In this case, we have already generated cleaned data from a previous experiment run; we can retrieve the cleaned data by referencing the tag of the particular run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines preprocessing action and resulting intermediary artifacts\n",
    "#TODO: double check syntax\n",
    "data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag=\"first\")\n",
    "data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data points, we need to perform a train/test split. Using the `traintest_split` function we imported earlier, let's create a flor action as well as the intermediary artifacts generated by the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintest_split is the function to run, data_x and data_y are arguments\n",
    "do_split = ex.action(traintest_split, [data_x, data_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artifacts have a pointer (filename), internal name, and (optional) parent\n",
    "X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "y_test = ex.artifact('y_test.json', 'y_test', do_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can specify the hyperparameter with a **literal**, an explicit value stored in Flor, and create an action for our `train_test` function and an artifact for our result. We can wrap up the experiment and close it with `__exit__()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "#Define the model training and evaluation action and final artifacts\n",
    "do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, hyperparameter])\n",
    "report = ex.artifact('report.csv', 'report', do_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.Experiment(\"risecamp_demo\").__exit__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull\n",
    "\n",
    "Finally, we are ready to run the experiment! We can do so by running `pull()` on our output artifacts. Before doing this, however, it is helpful to use `plot()` to generate a florplan, a graph representation of the artifact's lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"557pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 556.50 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-328 552.5,-328 552.5,4 -4,4\"/>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"90,-324 0,-324 0,-288 90,-288 90,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"45\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial.ipynb</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-90\" rx=\"43.5923\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train_test</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M39.8946,-287.8501C31.8937,-255.1735 20.539,-185.9504 54,-144 71.0866,-122.5783 141.342,-106.7053 190.9409,-97.8982\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.6172,-101.3333 200.8738,-96.1791 190.4233,-94.4359 191.6172,-101.3333\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"195\" cy=\"-234\" rx=\"58.4896\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">traintest_split</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;7 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M82.8513,-287.8314C104.5704,-277.4062 131.8501,-264.312 154.066,-253.6483\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"155.7455,-256.7245 163.2462,-249.2418 152.7164,-250.4139 155.7455,-256.7245\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"244.5,-324 127.5,-324 127.5,-288 244.5,-288 244.5,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_X.json</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188.2711,-287.8314C189.2336,-280.131 190.3782,-270.9743 191.4479,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.9309,-262.7702 192.6983,-252.4133 187.9849,-261.9019 194.9309,-262.7702\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"377,-324 263,-324 263,-288 377,-288 377,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_y.json</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.4572,-287.8314C271.2123,-277.8983 249.7607,-265.5422 231.7605,-255.1741\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"233.115,-251.9152 222.7028,-249.9568 229.6212,-257.9809 233.115,-251.9152\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"548.5,-180 441.5,-180 441.5,-144 548.5,-144 548.5,-180\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"441.5,-144 548.5,-144 \"/>\n",
       "<text text-anchor=\"middle\" x=\"495\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hyperparameters</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>10&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M441.2382,-146.3667C438.4526,-145.5645 435.6937,-144.7718 433,-144 383.5851,-129.8417 326.9069,-113.8485 288.2081,-102.9661\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.8562,-99.5127 278.2822,-100.176 286.962,-106.2515 288.8562,-99.5127\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"277.5,-36 206.5,-36 206.5,0 277.5,0 277.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">report.csv</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M242,-71.8314C242,-64.131 242,-54.9743 242,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.5001,-46.4132 242,-36.4133 238.5001,-46.4133 245.5001,-46.4132\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"141,-180 63,-180 63,-144 141,-144 141,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x_train.npz</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.9603,-216.937C161.2398,-207.8631 146.621,-196.5453 133.703,-186.5443\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"135.5571,-183.5534 125.5073,-180.1992 131.2719,-189.0885 135.5571,-183.5534\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"231,-180 159,-180 159,-144 231,-144 231,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x_test.npz</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M195,-215.8314C195,-208.131 195,-198.9743 195,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.5001,-190.4132 195,-180.4133 191.5001,-190.4133 198.5001,-190.4132\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"330.5,-180 249.5,-180 249.5,-144 330.5,-144 330.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"290\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_train.json</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M217.0337,-217.3008C229.1986,-208.081 244.5275,-196.4634 257.9915,-186.2591\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.2332,-188.9518 266.0888,-180.1222 256.005,-183.373 260.2332,-188.9518\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"423.5,-180 348.5,-180 348.5,-144 423.5,-144 423.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_test.json</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.6181,-220.1837C259.8654,-210.1331 297.8107,-196.0478 338.9728,-180.369\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"340.269,-183.6206 348.364,-176.7854 337.7733,-177.0806 340.269,-183.6206\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.3279,-143.8314C158.2142,-133.0898 184.6101,-119.5148 205.6692,-108.6844\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.3404,-111.7607 214.6326,-104.0747 204.139,-105.5357 207.3404,-111.7607\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M206.8601,-143.8314C212.383,-135.3707 219.0535,-125.1521 225.0922,-115.9014\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.0947,-117.7047 230.6301,-107.4177 222.233,-113.8783 228.0947,-117.7047\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277.8876,-143.8314C272.2471,-135.3707 265.4347,-125.1521 259.2676,-115.9014\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"262.071,-113.7968 253.6118,-107.4177 256.2467,-117.6797 262.071,-113.7968\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;1 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M349.6627,-143.8314C328.1797,-133.0898 301.0296,-119.5148 279.3688,-108.6844\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.6589,-105.4164 270.1493,-104.0747 277.5283,-111.6774 280.6589,-105.4164\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f36ec2d6cf8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving sparse matrices\n",
      "Loading Data\n",
      "Training Model\n",
      "Predicting Model\n",
      "Writing Results\n"
     ]
    }
   ],
   "source": [
    "#Run the experiment\n",
    "report.pull(\"first_pull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Flor makes it convenient to run models using different hyperparameters and track the results. In the `train_test` we created function, notice that we pass in `hyperparameters` in addition to the train and test data. These hyperparameters will allow us to tune our model and track results with ease; let's define them in our experiment setup.\n",
    "\n",
    "Notice that the Random Forest Classifier contains `n_estimators` as a hyperparameter. We would like to tune this hyperparameter and track model performance. In order to specify the hyperparameters, we must make a `literalForEach` within our experiment. **Fill in the `literalForEach` with values 5, 50 and 75 within the experiment below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: We have copied the same experiment below for convenience.\n",
    "#We can also create flor experiments using a context manager.\n",
    "\n",
    "# Create a context manager for the experiment and is named 'risecamp_demo'\n",
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    ex.groundClient('git') #use \"git\" from grit and \"ground\" for ground\n",
    "\n",
    "    # Defines artifacts\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag='first')\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag='first')\n",
    "\n",
    "    #Define split action and resulting output artifacts\n",
    "    do_split = ex.action(traintest_split, [data_x, data_y])\n",
    "    X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "    X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "    y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "    y_test = ex.artifact('y_test.json', 'y_test', do_split)\n",
    "\n",
    "    #Define the hyperparameters for the models\n",
    "    random_forest_Nestimators = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "#     random_forest_Nestimators = ex.literalForEach(v=[5, 50, 75], name=\"hyperparameters\", default=50) #SOLUTION\n",
    "\n",
    "    #Define the model training and evaluation action and final artifacts\n",
    "    do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, random_forest_Nestimators])\n",
    "    report = ex.artifact('report.csv', 'report', do_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"557pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 556.50 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-328 552.5,-328 552.5,4 -4,4\"/>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"90,-324 0,-324 0,-288 90,-288 90,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"45\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial.ipynb</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-90\" rx=\"43.5923\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train_test</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M39.8946,-287.8501C31.8937,-255.1735 20.539,-185.9504 54,-144 71.0866,-122.5783 141.342,-106.7053 190.9409,-97.8982\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.6172,-101.3333 200.8738,-96.1791 190.4233,-94.4359 191.6172,-101.3333\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"195\" cy=\"-234\" rx=\"58.4896\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">traintest_split</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;7 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M82.8513,-287.8314C104.5704,-277.4062 131.8501,-264.312 154.066,-253.6483\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"155.7455,-256.7245 163.2462,-249.2418 152.7164,-250.4139 155.7455,-256.7245\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"244.5,-324 127.5,-324 127.5,-288 244.5,-288 244.5,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_X.json</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188.2711,-287.8314C189.2336,-280.131 190.3782,-270.9743 191.4479,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.9309,-262.7702 192.6983,-252.4133 187.9849,-261.9019 194.9309,-262.7702\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"377,-324 263,-324 263,-288 377,-288 377,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data_clean_y.json</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.4572,-287.8314C271.2123,-277.8983 249.7607,-265.5422 231.7605,-255.1741\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"233.115,-251.9152 222.7028,-249.9568 229.6212,-257.9809 233.115,-251.9152\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"548.5,-180 441.5,-180 441.5,-144 548.5,-144 548.5,-180\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"441.5,-144 548.5,-144 \"/>\n",
       "<text text-anchor=\"middle\" x=\"495\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hyperparameters</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>10&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M441.2382,-146.3667C438.4526,-145.5645 435.6937,-144.7718 433,-144 383.5851,-129.8417 326.9069,-113.8485 288.2081,-102.9661\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.8562,-99.5127 278.2822,-100.176 286.962,-106.2515 288.8562,-99.5127\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"277.5,-36 206.5,-36 206.5,0 277.5,0 277.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">report.csv</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M242,-71.8314C242,-64.131 242,-54.9743 242,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.5001,-46.4132 242,-36.4133 238.5001,-46.4133 245.5001,-46.4132\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"141,-180 63,-180 63,-144 141,-144 141,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"102\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x_train.npz</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.9603,-216.937C161.2398,-207.8631 146.621,-196.5453 133.703,-186.5443\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"135.5571,-183.5534 125.5073,-180.1992 131.2719,-189.0885 135.5571,-183.5534\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"231,-180 159,-180 159,-144 231,-144 231,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"195\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x_test.npz</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M195,-215.8314C195,-208.131 195,-198.9743 195,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"198.5001,-190.4132 195,-180.4133 191.5001,-190.4133 198.5001,-190.4132\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"330.5,-180 249.5,-180 249.5,-144 330.5,-144 330.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"290\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_train.json</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M217.0337,-217.3008C229.1986,-208.081 244.5275,-196.4634 257.9915,-186.2591\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.2332,-188.9518 266.0888,-180.1222 256.005,-183.373 260.2332,-188.9518\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"423.5,-180 348.5,-180 348.5,-144 423.5,-144 423.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"386\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_test.json</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M232.6181,-220.1837C259.8654,-210.1331 297.8107,-196.0478 338.9728,-180.369\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"340.269,-183.6206 348.364,-176.7854 337.7733,-177.0806 340.269,-183.6206\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.3279,-143.8314C158.2142,-133.0898 184.6101,-119.5148 205.6692,-108.6844\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.3404,-111.7607 214.6326,-104.0747 204.139,-105.5357 207.3404,-111.7607\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M206.8601,-143.8314C212.383,-135.3707 219.0535,-125.1521 225.0922,-115.9014\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.0947,-117.7047 230.6301,-107.4177 222.233,-113.8783 228.0947,-117.7047\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277.8876,-143.8314C272.2471,-135.3707 265.4347,-125.1521 259.2676,-115.9014\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"262.071,-113.7968 253.6118,-107.4177 256.2467,-117.6797 262.071,-113.7968\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;1 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M349.6627,-143.8314C328.1797,-133.0898 301.0296,-119.5148 279.3688,-108.6844\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.6589,-105.4164 270.1493,-104.0747 277.5283,-111.6774 280.6589,-105.4164\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f36d71570b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving sparse matrices\n",
      "Loading Data\n",
      "Training Model\n",
      "Predicting Model\n",
      "Writing Results\n"
     ]
    }
   ],
   "source": [
    "#Run the experiment\n",
    "report.pull(utag=\"hyperparameter_tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking at Results\n",
    "\n",
    "After running the model with different hyperparameters above, we are able to peek at our output artifact, containing precision and recall metrics for the different models. Run the following cell - **which hyperparameter yields the best model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run me\n",
    "report.peek() #Depends on dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Better Model\n",
    "\n",
    "Now that you have some experience using flor, let's try using a different model to see if we can improve the results. Some of the classifiers we recommend trying are the Multilayer Perceptron Classifier, Naive Bayes Classifier, and K-neighbors Classifier.\n",
    "\n",
    "After implementing your model of choice in the `train_test` function in **florfunctions.py**, run the cells below to reimport the function and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from florfunctions import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: We have copied the same experiment below for convenience.\n",
    "#We can also create flor experiments using a context manager.\n",
    "\n",
    "# Create a context manager for the experiment and is named 'risecamp_demo'\n",
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    ex.groundClient('git') #use \"git\" from grit and \"ground\" for ground\n",
    "\n",
    "    # Defines artifacts\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag='first')\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag='first')\n",
    "\n",
    "    #Define split action and resulting output artifacts\n",
    "    do_split = ex.action(traintest_split, [data_x, data_y])\n",
    "    X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "    X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "    y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "    y_test = ex.artifact('y_test.json', 'y_test', do_split)\n",
    "\n",
    "    #Define the hyperparameters for the models\n",
    "    #hyperparameter = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "    random_forest_Nestimators = ex.literalForEach(v=[5, 50, 75], name=\"hyperparameters\", default=50) #SOLUTION\n",
    "    #MLP_hidden_layer_size = ex.literalForEach(v=[(1, ), (2, ), (3, )], name=\"hyperparameters\", default=(2, ))\n",
    "\n",
    "    #Define the model training and evaluation action and final artifacts\n",
    "    #change to MLP_hidden_layer_size \n",
    "    do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, random_forest_Nestimators])\n",
    "    #for naive bayes\n",
    "    #do_test = ex.action(train_test, [X_train, X_test, y_train, y_test])\n",
    "    report = ex.artifact('report.csv', 'report', do_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving sparse matrices\n",
      "Loading Data\n",
      "Training Model\n",
      "Predicting Model\n",
      "Writing Results\n",
      "Loading Data\n",
      "Training Model\n",
      "Predicting Model\n",
      "Writing Results\n",
      "Loading Data\n",
      "Training Model\n",
      "Predicting Model\n",
      "Writing Results\n"
     ]
    }
   ],
   "source": [
    "report.pull(utag=\"improved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mishaps\n",
    "\n",
    "It turns out, the data that we have been working had not been cleaned optimally to begin with. In fact, we can observe the exact cleaning process in the `pre-processing` function within florfunctions.py. We can re-clean raw data by adding another flor action and intermediate artifacts. Fortunately, however, we already ran an experiment with more optimal preprocessing. We can checkout the artifacts by using `utag = 'second'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag='first')\n",
    "data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the new data impacts our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: We have copied the same experiment below for convenience.\n",
    "\n",
    "# Create a context manager for the experiment and is named 'risecamp_demo'\n",
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    ex.groundClient('git') #use \"git\" from grit and \"ground\" for ground\n",
    "\n",
    "    # Defines artifacts\n",
    "    data_x = ex.artifact('data_clean_X.json', 'intermediate_X', utag='second')\n",
    "    data_y = ex.artifact('data_clean_y.json', 'intermediate_y', utag='second')\n",
    "\n",
    "    #Define split action and resulting output artifacts\n",
    "    do_split = ex.action(traintest_split, [data_x, data_y])\n",
    "    X_train = ex.artifact('x_train.npz', 'X_train', do_split)\n",
    "    X_test = ex.artifact('x_test.npz', 'X_test', do_split)\n",
    "    y_train = ex.artifact('y_train.json', 'y_train', do_split)\n",
    "    y_test = ex.artifact('y_test.json', 'y_test', do_split)\n",
    "\n",
    "    #Define the hyperparameters for the models\n",
    "    #hyperparameter = ex.literal(v = 5, name=\"hyperparameters\")\n",
    "    random_forest_Nestimators = ex.literalForEach(v=[5, 50, 75], name=\"hyperparameters\", default=50) #SOLUTION\n",
    "    #MLP_hidden_layer_size = ex.literalForEach(v=[(1, ), (2, ), (3, )], name=\"hyperparameters\", default=(2, ))\n",
    "\n",
    "    #Define the model training and evaluation action and final artifacts\n",
    "    #change to MLP_hidden_layer_size \n",
    "    do_test = ex.action(train_test, [X_train, X_test, y_train, y_test, random_forest_Nestimators])\n",
    "    #for naive bayes\n",
    "    #do_test = ex.action(train_test, [X_train, X_test, y_train, y_test])\n",
    "    report = ex.artifact('report.csv', 'report', do_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.pull(utag=\"better_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
